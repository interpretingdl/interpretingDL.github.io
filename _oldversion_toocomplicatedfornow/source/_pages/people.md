---
title: "People"
layout: single
classes: wide
permalink: /people
header:
  overlay_color: "#5e616c"
  overlay_image: /assets/images/network-bw-1.png
sidebar:
  nav: nav
---

All members of the network are actively working on interpretability, but they have come to this topic from very different domains. The network brings together crucial expertise on methodology, lexical semantics, semantic and syntactic parsing, machine translation, computational phonology, music recommendation, language acquisition and more. This will allow us to give different perspectives towards what interpretation of deep learning means in different scenerios and for different goals.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 15px; margin-bottom: 5px;" src="../assets/images/jelle2015.jpg">
**Willem Zuidema** is associate professor of computational linguistics and cognitive science at ILLC (UvA), with a long term interest in the neural basis of language. Because of that cognitive interest, was early contributor to deep learning in NLP, with work on neural parsing published as early as 2008 (Borensztajn & Zuidema, 2008, CogSci), and pioneering contributions on tree-shaped neural networks, including the TreeLSTM (Le & Zuidema {% cite le2015 -A %} <!--2015-->, \*SEM; published concurrently with groups from Stanford and Montreal). In 2016 he and his students introduced Diagnostic Classification {% cite veldhoen2016 hupkes2018 giulianelli2018 %} <!--(Veldhoen et al., 2016; Hupkes et al 2018; Giulianelli et al. 2018)-->, one of the key _interpretability_ techniques. He further performed research on the integration of formal logic and deep learning {% cite veldhoen2017 repplinger2018 mul2019 %} <!--(Veldhoen & Zuidema, 2017; Repplinger, Beinborn & Zuidema, 2018; Mul & Zuidema, 2019)-->. Other directly relevant work focuses on other _interpretability techniques_ including Representational Similarity Analysis {% cite abnar2019 %} <!--(Abnar et al., 2019)--> and contextual decomposition (Jumelet et al., 2019).

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 15px; margin-bottom: 5px;" src="../assets/images/alishahi.png">
**Afra Alishahi** is an Associate Professor of Cognitive Science and Artificial Intelligence at Tilburg University. Her main research interests are developing computational models for studying the process of human language acquisition, studying the emergence of linguistic structure in grounded models of language learning, and developing tools and techniques for analyzing linguistic representations in neural models of language. She has received a number of research grants including an NWO Aspasia, an NWO Natural Artificial Intelligence and an e-Science Center/NWO grant. She is the co-organizer of the BlackboxNLP 2018 workshop, the first official venue dedicated to analyzing and interpreting neural networks for NLP. She has a number of well-received publications on the topic of interpretability of neural network models of language, including the recipient of the best paper award at the Conference on Computational Language Learning (CoNLL) in 2017.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 15px; margin-bottom: 5px;" src="../assets/images/chrupała.jpg">
**Grzegorz Chrupała** is an associate professor at the Department of Cognitive Science and Artificial Intelligence at Tilburg University. His research focuses on computational models of language learning from multimodal signals such as speech and vision and on the analysis and interpretability of representations emerging in deep neural networks. He co-organized the first three editions of BlackboxNLP, the Workshop on Analyzing and Interpreting Neural Networks for NLP. Together with Afra Alishahi and students, he did some of the pioneering research on analyzing deep learning methods for visually grounded language {% cite kadar2017 %}<!--(Kádár, Chrupała and Alishahi 2017, CL)--> as well as for speech {% cite alishahi2017 %} <!--(Alishahi, Barking and Chrupała 2017, CoNLL)-->. His other recent work in the area of analysis and interpretation include {% cite chrupala2019 %} <!--(2019, ACL)--> introducing analytical methods based on Representational Similarity Analysis and Tree Kernels, and {% cite chrupala-etal-2020-analyzing %} featuring a detailed comparison of several analytical techniques applied to spoken language systems.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 10px; margin-bottom: 5px;" src="../assets/images/bisazza.jpg">
**Arianna Bisazza** is assistant professor at the Center for Language and Cognition (CLCG) of the University of Groningen, fully funded by a VENI grant since 2016 Her research aims at identifying intrinsic limitations of current language modeling paradigms, and to design robust NLP algorithms that can adapt to a diverse range of linguistic phenomena observed among the world's languages. She has a long track record of contributions to machine translation for challenging language pairs {% cite bisazza2012 tran2014 fadaee2017 %}
<!--(Bisazza & Federico 2012; Tran, Bisazza & Monz, 2014; Fadaee, Bisazza & Monz, 2016)-->. Together with colleagues at the University of Amsterdam, she proposed the Recurrent Memory Network, one of the very first modifications to deep-learning based language models aimed at improving interpretability {% cite tran2016 %}<!--(Tran, Bisazza & Monz, 2016)-->. Other recent contributions to the interpretability of NLP models include analyses of MT outputs {% cite bentivogli2018 %}<!--(Bentivogli et al., 2018)--> and probing tasks for recurrent language models {% cite tran2018 bisazza2018 %}<!--(Tran, Bisazza, and Monz, 2018; Bisazza & Tump, 2018)-->.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 10px; margin-bottom: 5px;" src="../assets/images/hupkes.jpg">
**Dieuwke Hupkes** is a research scientist at Facebook AI Research, and the scientific manager of the Amsterdam unit of ELLIS. Before that, she was a PhD student at the Institute for Logic, Language and Computation, working together with Willem Zuidema. In her research, she focuses on understanding how recurrent neural networks can understand and learn the types of hierarchical structures that occur in natural language, for her a problem that touches on the core of understanding natural language. Although artificial neural networks are of course nothing like the real brain, she hopes that understanding the principles by which they can encode processes can still teach us something that will lead to a better understanding of language!

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 10px; margin-bottom: 5px;" src="../assets/images/lentz.jpg">
**Tom Lentz** is an assistant professor in computational phonology and cognitive science at the ILLC of the UvA.  He works on the detection of prosodic structure in speech, including automatic classification of pitch contours as gathered in controlled experiments. He has recently obtained an interdisciplinary research grant for a project on the detection of irony in spoken speech (funding for one PhD student). Relevant other experience is an investigation on the individual variation in the use of prosody to mark focus {% cite lentz2015 %}<!--(Lentz & Chen, 2015)-->.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 15px; margin-bottom: 5px;" src="../assets/images/tenbosch.png">**Louis ten Bosch** (RU, Nijmegen) has expertise in automatic speech recognition, _computational modelling of cognitive processes_, speech decoding techniques using phonological features, and structure discovery methods. He is one of the coorganizers of the successful DNN interpretation session “what we learn from DNNs” that took place in 2018 at the language and speech technology conference Interspeech in Hyderabad, India. One of the recent advances in understanding artificial networks is achieved by relating the mathematical layer-to-layer transformations in a network to the more structural description of datasets as shown by linear mixed effect models and by Generalized Additive Models. More recently, in collaboration with Mirjam Ernestus, he is involved in computational models of human spoken word comprehension, a number of abstract-versus-exemplar studies in psycholinguistics, and (with Ton Dijkstra) in computational modelling of  online sentence processing of idiomatic expressions.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 15px; margin-bottom: 5px;" src="../assets/images/hendrickx.jpeg">
**Iris Hendrickx** (RU, Nijmegen) is a researcher in computational linguistics and digital humanities with a focus on the areas of machine learning, lexical and relational semantics, natural language processing, techniques for document understanding and text mining. She provides expertise to the network on creating text data enriched with human annotation for training such models, and on applying and evaluating these models and augmenting them with domain expert knowledge.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 15px; margin-bottom: 5px;" src="../assets/images/fokkens.jpg"> **Antske Fokkens** is an assistant professor in computational linguistics at the Vrije Universiteit. Her main expertise lie in methodological questions in computational linguistics and, in particular, the importance of understanding the implications of chosen technologies, training data and features when applying computational language models in interdisciplinary contexts. In her research she has (among others) pointed out fundamental problems with reproducibility {% cite fokkens2013 %}<!--(Fokkens et al. (2013))--> as well as the need for deeper analysis of the accuracy of our tools {% cite le2017 fokkens2017 %}<!--(Le and Fokkens, 2017; Fokkens et al. 2017)-->. She collaborates extensively with researchers in the humanities and social sciences, as can be seen in multiple joint publications, grants and events and is a member of the Computational Communication Science lab Amsterdam. She is a recognized international expert and has obtained multiple research grants, including a VENI grant in 2015 and co-applicantship of an NWO Vrije Competitie grant, as well as project funding from societal partners.

<img style="float: left; width: 20%; margin-right: 20px; margin-top: 15px; margin-bottom: 5px;" src="../assets/images/burgoyne.jpg">**John Ashley Burgoyne** is the Lecturer in Computational Musicology at the University of Amsterdam and researcher in the Music Cognition Group at the Institute for Logic, Language, and Computation. Cross-appointed in Musicology and Artificial Intelligence, he is interested in understanding musical behaviour at the audio level, using large-scale experiments and audio corpora. His McGill–Billboard corpus of time-aligned chord and structure transcriptions has served as a backbone for audio chord estimation techniques. His Hooked on Music project reached hundreds of thousands of participants in almost every country on Earth while collecting data to understand long-term musical memory.


## References

{% bibliography --cited %}
